# Rainbow DQN for []

We (Group 24) have implemented rainbow DQN with the following modifications:
- Double Deep Q Network
- Prioritised Experience Replay (implementation aided by Citation 1)
- Dueling Neural Networks
- Noisy Networks
- Categorical DQN
- n-step Learning

This implementation was helped along by [3] and [4]

## Requirements
to add



## Citations

1. segment_tree.py has been derived from [OpenAI's baseline library](https://github.com/openai/baselines) for use in Prioritised Experience Replay (https://github.com/openai/baselines)

2. Some of DeepQNetworkAgent.py was made with the help of [Deep Q Learning is Simple with PyTorch | Full Tutorial 2020 by "Machine Learning with Phil"](https://www.youtube.com/watch?v=wc-FxNENg9U)


3. Theoretical Background tied to code [rainbow-is-all-you-need GitHub repository](https://github.com/Curt-Park/rainbow-is-all-you-need)
(https://github.com/Curt-Park/rainbow-is-all-you-need)

4. Noisy Network implementation [NoisyNet A3C GitHub repositroy](https://github.com/Kaixhin/NoisyNet-A3C/tree/master)
(https://github.com/Kaixhin/NoisyNet-A3C/tree/master)

5. 